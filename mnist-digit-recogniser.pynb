#!/usr/bin/env python
# coding: utf-8

import keras
import tensorflow as tf

mnist = tf.keras.datasets.mnist #28x28 images of hand-written digits 0-9
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = tf.keras.utils.normalize(x_train, axis=1) # 0-1 range from 0-255
x_test = tf.keras.utils.normalize(x_test, axis=1)

model = tf.keras.models.Sequential() # our way of ML
model.add(tf.keras.layers.Flatten())   #our complexity 
# print(dir(tf.keras.layers))
model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))
model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))
model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))

model.compile(optimizer='adam',
             loss='sparse_categorical_crossentropy',
             matrics=['accuracy'])
history = model.fit(x_train, y_train, epochs=3)
# history.history['accuracy']

val_loss, val_acc = model.evaluate(x_test, y_test)
print(val_loss, val_acc)


import matplotlib.pyplot as plt
plt.imshow(x_train[0], cmap=plt.cm.binary)
# plt.show()
# print(x_train[0])
# print(x_test[0])

model.save('epic_num_reader.model')

new_model = tf.keras.models.load_model('epic_num_reader.model')
predictions = new_model.predict([x_test])
print(predictions)

import numpy as np
print(np.argmax(predictions[500]))
b = tf.math.argmax(predictions[2])
c = tf.keras.backend.eval(b)
print(c)

plt.imshow(x_test[500])
plt.show()
plt.imshow(x_test[2])
plt.show()


